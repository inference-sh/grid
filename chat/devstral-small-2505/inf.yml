name: devstral-small-2505
description: Devstral-Small-2505 is an agentic large language model (LLM) designed for software engineering tasks, developed through a collaboration between Mistral AI and All Hands AI. It is fine-tuned from Mistral-Small-3.1 and has a long context window of up to 128k tokens
category: chat
images:
    card: https://cloud.inference.sh/u/4mg21r6ta37mpaz6ktzwtt8krr/01jz008wnv226d2x18hxvb2wzh.png
    thumbnail: ""
    banner: ""
metadata: {}
variants:
    default:
        name: default
        order: 0
        resources:
            gpu:
                count: 1
                vram: 48000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q4:
        name: q4
        order: 1
        resources:
            gpu:
                count: 1
                vram: 16000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q4_0:
        name: q4_0
        order: 2
        resources:
            gpu:
                count: 1
                vram: 14000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q5:
        name: q5
        order: 3
        resources:
            gpu:
                count: 1
                vram: 20000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q8:
        name: q8
        order: 4
        resources:
            gpu:
                count: 1
                vram: 10000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
