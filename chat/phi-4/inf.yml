name: phi-4
description: Phi-4 14B
category: chat
images:
    card: https://cloud.inference.sh/u/01sm9vzqrjkvqhzx5xsybwce0y/01jzjxafvym2kdbrab06r2sn92.png
    thumbnail: ""
    banner: ""
metadata: {}
variants:
    default:
        name: bf16
        order: 0
        resources:
            gpu:
                count: 1
                vram: 48000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q3_k_l:
        name: q3_k_l
        order: 1
        resources:
            gpu:
                count: 1
                vram: 12000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q4_k:
        name: q4_k
        order: 2
        resources:
            gpu:
                count: 1
                vram: 16000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q6_k:
        name: q6_k
        order: 3
        resources:
            gpu:
                count: 1
                vram: 20000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q8_0:
        name: q8_0
        order: 4
        resources:
            gpu:
                count: 1
                vram: 24000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
