name: phi-4-14b
description: |
    phi-4 is a state-of-the-art open model built upon a blend of synthetic datasets, data from filtered public domain websites, and acquired academic books and Q&A datasets. The goal of this approach was to ensure that small capable models were trained with data focused on high quality and advanced reasoning.
category: chat
images:
    card: https://cloud.inference.sh/u/4mg21r6ta37mpaz6ktzwtt8krr/01jyzzn2v066ytws0s6221xjk5.png
    thumbnail: ""
    banner: ""
metadata: {}
variants:
    default:
        name: bf16
        order: 0
        resources:
            gpu:
                count: 1
                vram: 48000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q3_k_l:
        name: q3_k_l
        order: 1
        resources:
            gpu:
                count: 1
                vram: 12000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q4_k:
        name: q4_k
        order: 2
        resources:
            gpu:
                count: 1
                vram: 16000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q6_k:
        name: q6_k
        order: 3
        resources:
            gpu:
                count: 1
                vram: 20000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q8_0:
        name: q8_0
        order: 4
        resources:
            gpu:
                count: 1
                vram: 24000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
