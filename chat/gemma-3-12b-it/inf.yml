name: gemma-3-12b-it
description: Gemma 3 12B is a 12-billion-parameter vision-language model developed by Google, capable of handling text and image input and generating text output. It features a 128K context window, multilingual support, and open weights, making it suitable for tasks such as question answering, summarization, reasoning, and image understanding
category: chat
images:
    card: https://cloud.inference.sh/u/4mg21r6ta37mpaz6ktzwtt8krr/01jz022t6xqj5n0r3sr5yhpcrc.png
    thumbnail: ""
    banner: ""
metadata:
    capabilities:
        - image
variants:
    default:
        name: fp16
        order: 0
        resources:
            gpu:
                count: 1
                vram: 18000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
        python: "3.11"
    q4_k_m:
        name: q4_k_m
        order: 1
        resources:
            gpu:
                count: 1
                vram: 18000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
        python: "3.11"
    q8_0:
        name: q8_0
        order: 2
        resources:
            gpu:
                count: 1
                vram: 18000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
        python: "3.11"
