name: mistral-small-3-2-24b-it-2506
description: Mistral Small 3.2 24B Instruct 2506
category: chat
images:
    card: https://cloud.inference.sh/users/7fc33ab0-cf3b-4d36-bf92-a79d9e02087e/4b5f14pem8sng0n0kyhwgyf34j.jpg
    thumbnail: ""
    banner: ""
metadata:
    capabilities:
        - reasoning
        - image
variants:
    default:
        name: bf16
        order: 0
        resources:
            gpu:
                count: 1
                vram: 48000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q3_k_s:
        name: q3_k_s
        order: 1
        resources:
            gpu:
                count: 1
                vram: 12000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q4_k_m:
        name: q4_k_m
        order: 2
        resources:
            gpu:
                count: 1
                vram: 16000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q6_k:
        name: q6_k
        order: 3
        resources:
            gpu:
                count: 1
                vram: 20000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
    q8_0:
        name: q8_0
        order: 4
        resources:
            gpu:
                count: 1
                vram: 24000000000
                type: any
            ram: 4000000000
        env:
            CMAKE_ARGS: -DGGML_CUDA=on
            FORCE_CMAKE: "1"
        python: "3.11"
