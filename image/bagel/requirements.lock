accelerate==1.10.1
annotated-types==0.7.0
certifi==2025.8.3
charset-normalizer==3.4.3
click==8.2.1
contourpy==1.3.2
cycler==0.12.1
decord==0.6.0
einops==0.8.1
filelock==3.19.1
flash-attn @ https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9+cu126torch2.5-cp311-cp311-linux_x86_64.whl
fonttools==4.59.2
fsspec==2025.7.0
gitdb==4.0.12
gitpython==3.1.45
huggingface-hub==0.29.1
idna==3.10
inferencesh==0.4.2
jinja2==3.1.6
kiwisolver==1.4.9
markupsafe==3.0.2
matplotlib==3.7.0
mpmath==1.3.0
networkx==3.5
ninja==1.13.0
numpy==1.24.4
nvidia-cublas-cu12==12.4.5.8
nvidia-cuda-cupti-cu12==12.4.127
nvidia-cuda-nvrtc-cu12==12.4.127
nvidia-cuda-runtime-cu12==12.4.127
nvidia-cudnn-cu12==9.1.0.70
nvidia-cufft-cu12==11.2.1.3
nvidia-curand-cu12==10.3.5.147
nvidia-cusolver-cu12==11.6.1.9
nvidia-cusparse-cu12==12.3.1.170
nvidia-nccl-cu12==2.21.5
nvidia-nvjitlink-cu12==12.4.127
nvidia-nvtx-cu12==12.4.127
opencv-python==4.7.0.72
packaging==25.0
pillow==11.3.0
platformdirs==4.4.0
protobuf==6.32.0
psutil==7.0.0
pyarrow==11.0.0
pydantic==2.11.7
pydantic-core==2.33.2
pyparsing==3.2.3
python-dateutil==2.9.0.post0
pyyaml==6.0.2
regex==2025.7.34
requests==2.32.3
safetensors==0.4.5
scipy==1.10.1
sentencepiece==0.1.99
sentry-sdk==2.35.1
setuptools==80.9.0
setuptools-scm==9.2.0
six==1.17.0
smmap==5.0.2
sympy==1.13.1
tokenizers==0.21.4
torch==2.5.1
torchvision==0.20.1
tqdm==4.67.1
transformers==4.49.0
triton==3.1.0
typing-extensions==4.15.0
typing-inspection==0.4.1
urllib3==2.5.0
wandb==0.21.1
