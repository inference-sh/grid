pydantic >= 2.0.0 # required for inference.sh
inferencesh==0.2.7
torch
gguf>=0.13.0
tqdm
# diffusers
git+https://github.com/huggingface/diffusers.git@5ffb73d4aeac9eaef8366d7b21872d64009bd1c7
transformers
huggingface_hub
accelerate
sentencepiece
protobuf
Pillow
einops
accelerate
python-dateutil
peft
hf_transfer

https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3+cu128torch2.9-cp311-cp311-linux_x86_64.whl