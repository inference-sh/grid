{
  "$defs": {
    "File": {
      "description": "A class representing a file in the inference.sh ecosystem.",
      "properties": {
        "uri": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Uri"
        },
        "path": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Path"
        },
        "content_type": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Content Type"
        },
        "size": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Size"
        },
        "filename": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "default": null,
          "title": "Filename"
        }
      },
      "title": "File",
      "type": "object"
    }
  },
  "properties": {
    "prompt": {
      "description": "Text prompt for video generation",
      "title": "Prompt",
      "type": "string"
    },
    "input_image": {
      "$ref": "#/$defs/File",
      "description": "Input image for image-to-video generation"
    },
    "end_frame": {
      "anyOf": [
        {
          "$ref": "#/$defs/File"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "Optional end frame image for video generation"
    },
    "size": {
      "default": "832x480",
      "description": "Size of the generated video (width*height)",
      "title": "Size",
      "type": "string"
    },
    "num_frames": {
      "default": 81,
      "description": "Number of frames to generate (should be 4n+1)",
      "title": "Num Frames",
      "type": "integer"
    },
    "fps": {
      "default": 16,
      "description": "Frames per second for the output video",
      "title": "Fps",
      "type": "integer"
    },
    "guidance_scale": {
      "default": 5.0,
      "description": "Classifier-free guidance scale",
      "title": "Guidance Scale",
      "type": "number"
    },
    "num_inference_steps": {
      "default": 30,
      "description": "Number of denoising steps",
      "title": "Num Inference Steps",
      "type": "integer"
    },
    "seed": {
      "anyOf": [
        {
          "type": "integer"
        },
        {
          "type": "null"
        }
      ],
      "default": -1,
      "description": "Random seed for reproducibility (-1 for random)",
      "title": "Seed"
    },
    "negative_prompt": {
      "default": "",
      "description": "Negative prompt to guide generation",
      "title": "Negative Prompt",
      "type": "string"
    },
    "sample_solver": {
      "default": "unipc",
      "description": "Solver to use for sampling (unipc or dpm++)",
      "title": "Sample Solver",
      "type": "string"
    },
    "shift": {
      "default": 5.0,
      "description": "Noise schedule shift parameter",
      "title": "Shift",
      "type": "number"
    },
    "tea_cache": {
      "default": 2.0,
      "description": "TeaCache multiplier (0 to disable, 1.5-2.5 recommended for speed)",
      "title": "Tea Cache",
      "type": "number"
    },
    "tea_cache_start_step_perc": {
      "default": 0,
      "description": "TeaCache starting step percentage",
      "title": "Tea Cache Start Step Perc",
      "type": "integer"
    },
    "lora_file": {
      "anyOf": [
        {
          "type": "string"
        },
        {
          "type": "null"
        }
      ],
      "default": null,
      "description": "URL to Lora file in safetensors format",
      "title": "Lora File"
    },
    "lora_multiplier": {
      "default": 1.0,
      "description": "Multiplier for the Lora effect",
      "title": "Lora Multiplier",
      "type": "number"
    },
    "vae_tile_size": {
      "default": 128,
      "description": "VAE tile size for lower VRAM usage (0, 128, or 256)",
      "title": "Vae Tile Size",
      "type": "integer"
    },
    "enable_RIFLEx": {
      "default": true,
      "description": "Enable RIFLEx positional embedding for longer videos",
      "title": "Enable Riflex",
      "type": "boolean"
    },
    "joint_pass": {
      "default": true,
      "description": "Enable joint pass for 10% speed boost",
      "title": "Joint Pass",
      "type": "boolean"
    },
    "attention": {
      "default": "sage",
      "description": "Attention mechanism to use for generation",
      "enum": [
        "sage",
        "sdpa"
      ],
      "title": "Attention",
      "type": "string"
    },
    "cfg_star_switch": {
      "default": true,
      "description": "Enable CFG* guidance",
      "title": "Cfg Star Switch",
      "type": "boolean"
    },
    "cfg_zero_step": {
      "default": 5,
      "description": "Step at which to switch to CFG* guidance",
      "title": "Cfg Zero Step",
      "type": "integer"
    },
    "add_frames_for_end_image": {
      "default": true,
      "description": "Add frames for end image in image-to-video",
      "title": "Add Frames For End Image",
      "type": "boolean"
    },
    "temporal_upsampling": {
      "default": "",
      "description": "Temporal upsampling method",
      "enum": [
        "",
        "rife2",
        "rife4"
      ],
      "title": "Temporal Upsampling",
      "type": "string"
    },
    "spatial_upsampling": {
      "default": "",
      "description": "Spatial upsampling method",
      "enum": [
        "",
        "lanczos1.5",
        "lanczos2"
      ],
      "title": "Spatial Upsampling",
      "type": "string"
    }
  },
  "required": [
    "prompt",
    "input_image"
  ],
  "title": "AppInput",
  "type": "object"
}