pydantic==2.10.6
inferencesh
torch>=2.7.0
torchvision>=0.20.0
torchaudio
diffusers
transformers
tokenizers
accelerate
numpy>=1.23.5,<2
imageio
imageio-ffmpeg
safetensors
huggingface_hub
hf_transfer
ftfy
gguf
peft
https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3+cu128torch2.9-cp311-cp311-linux_x86_64.whl